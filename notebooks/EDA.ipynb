{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, linewidth=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directory with training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('/home/mc/dev/dfdc_train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = list(train_dir.glob('*/*.json'))\n",
    "dfs = []\n",
    "for m in metadata:\n",
    "    dfs.append(pd.read_json(m, orient='index').rename_axis('file').reset_index())\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mp4 path to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filepath'] = np.nan\n",
    "df['filepath'] = df['filepath'].astype(object)\n",
    "for i in range(len(df)):\n",
    "    file = df.loc[i, 'file']\n",
    "    mp4s = list(train_dir.glob(f'*/{file}'))\n",
    "    if len(mp4s) > 0:\n",
    "        df.at[i, 'filepath'] = mp4s[0].as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For originals, add list of fakes to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fakes'] = np.nan\n",
    "df['fakes'] = df['fakes'].astype(object)\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'label'] == 'REAL':\n",
    "        file = df.loc[i, 'file']\n",
    "        fakes = df[df['original'] == file]['file'].to_list()\n",
    "        df.at[i, 'fakes'] = fakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/home/mc/dev/deepfake-detection-challenge/notebooks/master_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/mc/dev/deepfake-detection-challenge/notebooks/master_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get real videos and plot distribution of fakes per real video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_df = df[df['label'] == 'REAL'].reset_index()\n",
    "num_fakes = []\n",
    "for i in range(len(real_df)):\n",
    "    num_fakes.append(len(real_df.loc[i, 'fakes']))\n",
    "plt.hist(num_fakes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for converting mp4 files to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp4_to_npy(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    if not cap.isOpened(): \n",
    "        return np.array([])\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        else: break\n",
    "    return np.stack(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find regions of frames where real videos differ from fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "\n",
    "real_video_name = real_df.loc[i, 'file']\n",
    "real_video_path = real_df.loc[i, 'filepath']\n",
    "fake_video_name = real_df.loc[i, 'fakes'][j]\n",
    "fake_video_path = df[df['file'] == fake_video_name]['filepath'].iloc[0]\n",
    "\n",
    "print(real_video_name, real_video_path)\n",
    "real_video = mp4_to_npy(real_video_path)\n",
    "print(fake_video_name, fake_video_path)\n",
    "fake_video = mp4_to_npy(fake_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = fake_video.astype(float) - real_video.astype(float)\n",
    "diff = np.absolute(diff).astype('uint8')\n",
    "cutoff = 7 * np.ceil(np.mean(diff) + np.std(diff)).astype('uint8')\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh_diff(img1, img2, cutoff):\n",
    "    i1 = cv2.blur(img1, (11,11))\n",
    "    i2 = cv2.blur(img2, (11,11))\n",
    "    diff = i1.astype(np.float32) - i2.astype(np.float32)\n",
    "    abs_diff = np.absolute(diff).astype('uint8')\n",
    "    #cutoff = std_cutoff * np.ceil(np.mean(diff) + np.std(diff)).astype('uint8')\n",
    "    x, y, _ = (diff > cutoff).nonzero()\n",
    "    x1 = min(x)\n",
    "    x2 = max(x)\n",
    "    y1 = min(y)\n",
    "    y2 = max(y)\n",
    "    x = int((x1 + x2) / 2)\n",
    "    y = int((y1 + y2) / 2)\n",
    "    w = int(x2 - x1)\n",
    "    h = int(y2 - y1)\n",
    "    return x, y, w, h, img1[x1:x2, y1:y2], img2[x1:x2, y1:y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = real_video[0]\n",
    "img2 = fake_video[0]\n",
    "x, y, w, h, i1, i2 = xywh_diff(img1, img2, 30)\n",
    "print(x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_diff_coords(video1, video2, cutoff):\n",
    "    coords = []\n",
    "    for i, j in zip(video1, video2):\n",
    "        x, y, w, h, _, _ = xywh_diff(i, j, cutoff)\n",
    "        coords.append(np.array([x, y, w, h]))\n",
    "    return np.stack(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = video_diff_coords(real_video, fake_video, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = max(coords[:, 2])\n",
    "height = max(coords[:, 3])\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h, i1, i2 = xywh_diff(real_video[0], fake_video[0], 10)\n",
    "print(x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.absolute(i2.astype(float) - i1.astype(float)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.absolute(real_video[0].astype(float) - fake_video[0].astype(float)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.GaussianBlur(diff, (11,11), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(cv2.GaussianBlur(diff, (11,11), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_video[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = torch.Tensor(real_video[0].transpose(2, 0, 1).astype(np.float32)) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): pred = model([test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img.permute(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coords_on_img(img, coords):\n",
    "    im = img.copy()\n",
    "    for coord in coords:\n",
    "        cv2.circle(im, tuple(coord), 10, (255, 0, 0), -1, 3)\n",
    "    return im\n",
    "\n",
    "def plot_box_on_img(img, coords):\n",
    "    im = img.copy()\n",
    "    cv2.rectangle(im, tuple(coords[:2]), tuple(coords[2:]), (255, 0, 0), 10)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_img = test_img.permute(1, 2, 0).numpy()\n",
    "coords = pred[0]['keypoints'][0].numpy().astype(int)[:, :2]\n",
    "box = pred[0]['boxes'][0].numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plot_coords_on_img(ann_img, coords)\n",
    "img = plot_box_on_img(img, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate face keypoints for real and fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acscknxbjl.mp4 /home/mc/dev/dfdc_train/dfdc_train_part_25/acscknxbjl.mp4\n",
      "piaybeiamv.mp4 /home/mc/dev/dfdc_train/dfdc_train_part_25/piaybeiamv.mp4\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "\n",
    "real_video_name = real_df.loc[i, 'file']\n",
    "real_video_path = real_df.loc[i, 'filepath']\n",
    "fake_video_name = real_df.loc[i, 'fakes'][j]\n",
    "fake_video_path = df[df['file'] == fake_video_name]['filepath'].iloc[0]\n",
    "\n",
    "print(real_video_name, real_video_path)\n",
    "real_video = mp4_to_npy(real_video_path)\n",
    "print(fake_video_name, fake_video_path)\n",
    "fake_video = mp4_to_npy(fake_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "print('Model ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_face_coords(pred):\n",
    "    keypoints = pred['keypoints'][0][:5, :2].cpu().numpy() # nose, left_eye, right_eye, left_ear, right_ear\n",
    "    scores = pred['keypoints_scores'][0][:5].cpu().numpy()\n",
    "    scores = np.expand_dims(scores, 1)\n",
    "    return np.hstack((keypoints, scores))\n",
    "\n",
    "def video_to_face_coords(video):\n",
    "    model_inp = torch.Tensor(video.transpose(0, 3, 1, 2).astype('float32') / 255.0)\n",
    "    preds = []\n",
    "    for i in model_inp:\n",
    "        with torch.no_grad():\n",
    "            pred = model([i.cuda()])\n",
    "            preds.append(pred[0])\n",
    "    preds = np.stack([output_to_face_coords(i) for i in preds])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.57s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pred = video_to_face_coords(real_video)\n",
    "print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
